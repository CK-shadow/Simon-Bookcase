---
title: 初识Kafka
tags: 
 - Kafka
categories: frontEnd
---

> Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息

## Kafka登场
### 消息和批次
Kafka的数据单元被称为消息，消息由字节数组组成，对Kafka来说，消息里的数据没有什么特殊的含义。消息可以有一个可选的元数据，也就是键，同样是一个字节数组，对Kafka来说也没有什么含义

&emsp;  
为了提高效率，消息被分批次写入Kafka。批次就是一组消息，这些消息属于同一个主题或分区，分批次传输可以减少网络开销。不过，这要在时间传输和吞吐量之间做出权衡；批次越大，单位时间内处理的消息就越多，单个消息的传输时间就长。批次数据会被压缩，这样可以提升数据的传输和存储能力，但需要做更多的计算处理

### 模式
Kafka的许多开发者喜欢用Apache Avro，它最初是为Hadoop开发的一款序列化框架。Avro提供了一种紧凑的序列化格式，模式和消息体是分开的，当模式发生改变时，不需要重新生成代码；它还支持类型和模式进化，其版本既向前兼容，也向后兼容

### 主题和分区
Kafka的消息通过主题进行分类，主题可以被分为若干个分区，一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取。要注意，由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。Kafka通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说，一个主题可以横跨多个服务器，以此来提供比单个服务器更强大的性能

### 生产者和消费者
Kafka的客户端就是Kafka系统的用户，它们被分为两种基本类型：生产者和消费者。除此之外，还有其它高级客户端API，用于数据集成的Kafka Connect API和用于流式处理的Kafka Streams。这些高级客户端API使用生产者和消费者作为内部组件，提供了高级的功能

&emsp;  
生产者创建消息。一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把所有的消息均衡分布到主题的所有分区上，而并不关系特定消息会被写到哪个分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区

&emsp;  
消费者读取消息，消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失

&emsp;  
消费者是消费者群组的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用。消费者与分区之间的映射通常被称为消费者对分区的所有权关系。通过这种方式，消费者可以消费包含大量消息的主题，而且，如果一个消费者失效，群组里的其它消费者可以接管失效消费者的工作

### broker和集群
一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。broker为消息提供服务，对读取分区的请求做出响应，返回已经提交到磁盘上的消息。根据特定的硬件及其性能特征，单个broker可以轻松处理数千个分区以及每秒百万级的消息量

&emsp;  
broker是集群的组成部分，每个集群都有一个broker同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的首领。一个分区可以分配给多个broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个broker失效，其它broker可以接管领导权。不过，相关的消费者和生产者都要重新连接到新的首领

&emsp;  
保留消息（在一定期限内）是Kafka的一个重要特性。Kafka broker默认的消息保留策略是这样的：要么保留一段时间（比如7天），要么保留到消息达到一定大小的字节数（比如1GB）。当消息数量达到这些上限时，旧消息就会过期并删除，所以在任何时刻，可用的消息的总量都不会超过配置参数所指定的大小。主题可以配置自己的保留策略，可以将消息保留到不再使用他们为止

### 多集群
随着Kafka部署数量的增加，基于以下几点原因，最好使用多个集群：
* 数据类型分离
* 安全需求隔离
* 多数据中心（灾难恢复）

如果使用多个数据中心，就需要在它们之间复制消息。这样，在线应用程序才可以访问到多个站点的用户活动信息。Kafka提供了一个叫MirrorMaker的工具，可以用它来实现集群间的消息复制。MirrorMaker的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连。消费者从一个集群读取消息，生产者把消息发送到另一个集群上

## 为什么选择Kafka
### 多个生产者
Kafka可以无缝地支持多个生产者，不管客户端在使用单个主题还是多个主题。所以它很适合用来从多个前端系统收集数据，并以统一的格式对外提供数据

### 多个消费者
除了支持多个生产者外，Kafka也支持多个消费者从一个单独的消息流上读取数据，而且消费者之间直不影响。这与其他队列系统不同，其他队列系统的消息一旦被一个客户端读取，其他客户端就无法再读取它。另外，多个消费者可以组成一个群组，它们共享一个消息流，并保证整个群组对每个给定的消息只处理一次

### 基于磁盘的数据存储
Kafka不仅支持多个消费者，还允许消费者非实时地读取消息，这要归功于Kafka的数据保留特性。消息被提交到磁盘，根据设置的保留规则进行保存。每个主题可以设置单独的保留规则，以便满足不同消费者的需求，各个主题可以保留不同数量的消息。消费者可能会因为处理速度慢或突发的流量高峰导致无陆及时读取消息，而持久化数据可以保证数据不会丢失。消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵塞在生产者端。消费者可以被关闭，但消息会继续保留在Kafka里。消费者可以从上次中断的地方继续处理消息

### 伸缩性
为了能够轻松处理大量数据，Kafka从一开始就被设计成一个具有灵活伸缩性的系统。用户在开发阶段可以先使用单个broker，再扩展到包含3个broker的小型开发集群，然后随着数据盐不断增长，部署到生产环境的集群可能包含上百个broker。对在线集群进行扩展丝毫不影响整体系统的可用性。也就是说，一个包含多个broker的集群，即使个别broker失效，仍然可以持续地为客户提供服务。要提高集群的容错能力，需要配置较高的复制系数。

### 高性能
上面提到的所有特性，让Kafka成为了一个高性能的发布与订阅消息系统。通过横向扩展生产者、消费者和broker, Kafka可以轻松处理巨大的消息流。在处理大量数据的同时， 它还能保证亚秒级的消息延迟


