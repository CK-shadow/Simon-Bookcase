---
title: 可靠的数据传递
tags: 
 - Kafka
categories: frontEnd
---

## 可靠性保证
可靠性保证指的是指确保系统在各种不同的环境下能够发生一致的行为

&emsp;  
Kafka的保证机制有：
* Kafka可以保证分区消息的顺序。如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入，那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B
* 只有当消息被写入分区的所有同步副本时（但不一定要写入磁盘），它才被认为是"已提交"的。生产者可以选择接收不同类型的确认，比如在消息被完全提交时的确认，或者在消息被写入首领副本时的确认，或者在消息被发送到网络时的确认
* 只要还有一个副本是活跃的，那么已经提交的消息就不会丢失
* 消费者只能读取已经提交的消息

这些基本的保证机制可以用来构建可靠的系统，但仅仅依赖它们是无法保证系统完全可靠的。构建一个可靠的系统需要作出一些权衡，Kafka管理员和开发者可以在配置参数上作出权衡，从而得到他们想要达到的可靠性。这种权衡一般是指消息存储的可靠性和一致性的重要程度与可用性、高吞吐量、低延迟和硬件成本的重要程度之间的权衡

## 复制
Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。把消息写入多个副本可以使Kafka在发生崩溃时仍能保证消息的持久性。Kafka的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，Kafka可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领

&emsp;  
分区首领是同步副本，而对于跟随者副本来说，它需要满足以下条件才能被认为是同步的:
* 与Zookeeper之间有一个活跃的会话，也就是说，它在过去的6s（可配置）内向Zookeeper发送过心跳
* 在过去的10s内（可配置）从首领那里获取过消息
* 在过去的10s内从首领那里获取过最新的消息。光从首领那里获取消息是不够的，它还必须是几乎零延迟的

一个滞后的同步副本会导致生产者和消费者变慢，因为在消息被认为已提交之前，客户端会等待所有同步副本接收消息。而如果一个副本不再同步了，我们就不再关心它是否已经收到消息。虽然非同步副本同样滞后，但它并不会对性能产生任何影响。但是，更少的同步副本意味着更低的有效复制系数，在发生岩机时丢失数据的风险更大 
